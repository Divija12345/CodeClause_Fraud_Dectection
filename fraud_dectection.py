# -*- coding: utf-8 -*-
"""Fraud_Dectection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10MKgsiaegkAoodN8cLF36tuptL58xPcU

# Importing Dependencies
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""## Loading to a pandas dataframe"""

from google.colab import drive
drive.mount('/content/drive')

data= pd.read_csv('/content/drive/MyDrive/Fraud dectection/fraud-data.csv')

data.head()

"""# Dataset Information"""

data.info()

# Checking if there are missing values
data.isnull().sum()

"""## Distribution of fraudulant and legitimate transactions"""

data['Class'].value_counts()

sns.countplot(data['Class'])

"""Thus this dataset is highly unbalanced.

0 -> Normal Transaction


1 -> Fraud Transaction
"""

corrmat=data.corr()
plt.figure(figsize=(10,10))
sns.heatmap(corrmat,vmax=0.8, square=True )
plt.show



sns.jointplot(data['Time'],data['Amount'])

"""## Separating legitimate instances from fraud instances"""

fraud= data[data.Class == 1]
legit= data[data.Class == 0]

print(legit.Amount.describe())
print(fraud.Amount.describe())

data.groupby('Class').mean()

"""# Under-Sampling

We are going to built sample dataset of similar distribution of normal and fraud transactions
"""

legit_sample = legit.sample(n= 492)

new_dataset= pd.concat([legit_sample, fraud], axis= 0) # making the new dataset

new_dataset

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

"""Hence it has not changed much. Hence, we can proceed with this dataset.

## Splitting the dataset into features and target variables
"""

X= new_dataset.drop(columns= 'Class', axis=1)
y= new_dataset['Class']

X

y

"""## Split the dataset into training and testing"""

X_train, X_test, y_train, y_test= train_test_split(X,y, test_size= 0.2, stratify= y, random_state= 6)

"""# Model Training"""

model= LogisticRegression()

model.fit(X_train, y_train)

"""# Evaluation"""

X_train_prediction = model.predict(X_train)
training_accuracy = accuracy_score(X_train_prediction, y_train)
print('Accuracy on training data = ', training_accuracy)

X_test_prediction = model.predict(X_test)
test_accuracy = accuracy_score(X_test_prediction, y_test)
print('Accuracy on test data = ', test_accuracy)

